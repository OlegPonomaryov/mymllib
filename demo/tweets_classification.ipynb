{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=600 src=\"images/plane.jpeg\">\n",
    "<p>This notebook focuses on text classification using a naive Bayes classifier. The <a href=\"https://www.kaggle.com/crowdflower/twitter-airline-sentiment\">Twitter US Airline Sentiment</a> dataset, which contains tweets labeled by their sentiment, is used as an example.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import preprocessor as p\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import mymllib\n",
    "import mymllib.metrics.classification as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before proceeding, please, download the dataset using the link above and extract it to <i>twitter_airline_sentiment</i> directory like this:</p>\n",
    "<p><i>\n",
    "./twitter_airline_sentiment/<br/>\n",
    "├── database.sqlite<br/>\n",
    "└── Tweets.csv<br/>\n",
    "</i></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains many columns, but we'll need only tweet text and sentiment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_table(\n",
    "    \"./twitter_airline_sentiment/Tweets.csv\",\n",
    "    sep=\",\")[[\"text\", \"airline_sentiment\"]]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are labeled by sentiment as negative, neutral or positive. The classes are unbalanced, with positive one being the least represented: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode sentiment with numeric labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.                  1\n",
       "1  @VirginAmerica plus you've added commercials t...                  2\n",
       "2  @VirginAmerica I didn't today... Must mean I n...                  1\n",
       "3  @VirginAmerica it's really aggressive to blast...                  0\n",
       "4  @VirginAmerica and it's a really big bad thing...                  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.airline_sentiment = dataset.airline_sentiment.astype(\"category\").cat.codes\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here we define a preprocessing pipeline with following steps:</p>\n",
    "<ol>\n",
    "    <li>\n",
    "        Use <i>tweet-preprocessor</i> package to remove:\n",
    "        <ul>\n",
    "            <li>URLs</li>\n",
    "            <li>Hashtags</li>\n",
    "            <li>Mentions</li>\n",
    "            <li>Reserved words (RT, FAV)</li>\n",
    "            <li>Emojis</li>\n",
    "            <li>Smileys</li>\n",
    "            <li>Numbers</li>\n",
    "        </ul>\n",
    "    <li>Convert to lowercase</li>\n",
    "    <li>Remove stopwords and words that contain digits</li>\n",
    "    <li>Remove punctuation</li>\n",
    "    <li>Apply Snowball stemmer</li>\n",
    "</ol>\n",
    "<p>The pipeline can be improved, for example, to fix/remove misspelled words, but for a baseline model these steps should suffice.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "STOP_WORDS = get_stop_words(LANGUAGE)\n",
    "STEMMER = SnowballStemmer(LANGUAGE)\n",
    "REMOVE_PUNCTUATION = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def preprocess(tweet):\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = \" \".join(word for word in tweet.split()\n",
    "                     if word not in STOP_WORDS and not any(c.isdigit() for c in word))\n",
    "    tweet = tweet.translate(REMOVE_PUNCTUATION)\n",
    "    tweet = STEMMER.stem(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how the preprocessing works with a single tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tweet: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
      "Preprocessed tweet: plus added commercials experience tacki\n"
     ]
    }
   ],
   "source": [
    "source_tweet = dataset.text[1]\n",
    "preprocessed_tweet = preprocess(source_tweet)\n",
    "\n",
    "print(\"Source tweet:\", source_tweet)\n",
    "print(\"Preprocessed tweet:\", preprocessed_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all tweets in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus added commercials experience tacki</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really big bad th</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment\n",
       "0                                               said                  1\n",
       "1            plus added commercials experience tacki                  2\n",
       "2             today must mean need take another trip                  1\n",
       "3  really aggressive blast obnoxious entertainmen...                  0\n",
       "4                                  really big bad th                  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.text = dataset.text.map(preprocess)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to perform a train/test split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 11712\n",
      "Test dataset size: 2928\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=123)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"Train dataset size:\", train_dataset.shape[0])\n",
    "print(\"Test dataset size:\", test_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vocabulary is required to replace words with numeric tokens. It is built using only the train subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10434\n",
      "Vocabulary sample: ['a', 'aa', 'aaaand', 'aadavantage', 'aadfw', 'aadvantage', 'aal', 'aampc', 'aaron', 'aas', 'aaus', 'ab', 'aback', 'abandon', 'abandoned', 'abandonment', 'abassinet', 'abbrev', 'abc', 'abcdef', 'abcs', 'abducted', 'abi', 'abidfw', 'abilities', 'ability', 'able', 'aboard', 'abounds', 'about']\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(word for text in train_dataset.text for word in text.split())\n",
    "idx_to_word = sorted(unique_words)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(idx_to_word)}\n",
    "\n",
    "print(\"Vocabulary size:\", len(idx_to_word))\n",
    "print(\"Vocabulary sample:\", idx_to_word[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets and their labels are separeted and all words in tweets are replaced with their indices in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (11712, 21), train y shape: (11712,)\n",
      "Test X shape: (2928, 21), test y shape: (2928,)\n"
     ]
    }
   ],
   "source": [
    "PADDING_VALUE = -1\n",
    "\n",
    "def get_x_y(dataset, word_to_idx):\n",
    "    max_len = max(len(text.split()) for text in dataset.text)\n",
    "    x = []\n",
    "    for text in dataset.text:\n",
    "        idx = [word_to_idx[word] for word in text.split() if word in word_to_idx]\n",
    "        idx += [PADDING_VALUE] * (max_len - len(idx))\n",
    "        x.append(idx)\n",
    "    return np.asarray(x), dataset.airline_sentiment.to_numpy()\n",
    "\n",
    "X_train, y_train = get_x_y(train_dataset, word_to_idx)\n",
    "X_test, y_test = get_x_y(test_dataset, word_to_idx)\n",
    "\n",
    "print(f\"Train X shape: {X_train.shape}, train y shape: {y_train.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}, test y shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can train the naive Bayes text classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = mymllib.nlp.NaiveBayesTextClassifier()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8495560109289617\n",
      "Train balanced accuracy: 0.7699964802630902\n",
      "\n",
      "Test accuracy: 0.7520491803278688\n",
      "Test balanced accuracy 0.6119290791743199\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = naive_bayes.predict(X_train)\n",
    "y_test_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy:\", metrics.accuracy(y_train, y_train_pred))\n",
    "print(\"Train balanced accuracy:\", metrics.balanced_accuracy(y_train, y_train_pred))\n",
    "print()\n",
    "print(\"Test accuracy:\", metrics.accuracy(y_test, y_test_pred))\n",
    "print(\"Test balanced accuracy\", metrics.balanced_accuracy(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves a balanced accuracy of 61% and an unbalanced one of 75%. While this is definetely not the best result possible, it's quite good for such simple preprocessing pipeline and model. The naive Bayes is also much faster to train compared to advanced deep learning models, which makes it a good option to be used as a baseline model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
